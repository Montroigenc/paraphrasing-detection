{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyect 2: Álvaro Romero Díaz and Aleix Toda Mas\n",
    "\n",
    "### Syntactic dimension\n",
    "- Triples\n",
    "\n",
    "### Lexical dimensions used:\n",
    "- Words\n",
    "- Lemmas\n",
    "\n",
    "### Comparison metrics used:\n",
    "\n",
    "- Difflib\n",
    "- Tf/Idf\n",
    "- Cosine distance\n",
    "\n",
    "### Description \n",
    "\n",
    "Our idea is to build a vector for each pair of senteces, where we can store all results of comparison metrics and the labels, knowing if the sentences are paraphrase or not.\n",
    "\n",
    "After that, we can create a matrix of data and use it to build a ML model.\n",
    "\n",
    "When we have te model, we can test it with the test file provided.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet_ic\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "import warnings\n",
    "import io\n",
    "import unicodedata\n",
    "import nltk\n",
    "import re\n",
    "import difflib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "vect = TfidfVectorizer(min_df=1)\n",
    "WORD = re.compile(r'\\w+')\n",
    "stopWords = stopwords.words('english')\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For cosine distance\n",
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "#For cosine distance\n",
    "def text_to_vector(text):\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "#Print results\n",
    "def printResults(y_true, y_pred, TN, FP, FN, TP):\n",
    "    okCount = 0\n",
    "    nokCount = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            okCount += 1\n",
    "        else:\n",
    "            nokCount += 1\n",
    "    acc = (TP + TN) / float(TP + TN + FP + FN)\n",
    "    reject = TN / float(TN + FP)\n",
    "    accept = TP / float(TP + FN)\n",
    "    print str(name)\n",
    "    print \"    acc= \", acc, \" reject= \", reject, \" accept= \", accept\n",
    "    print \"    Matched results:    \", okCount, \"          \", round(okCount / (okCount + nokCount) * 100, 2), \"%\"\n",
    "    print \"    No matched results: \", nokCount, \"          \", round(nokCount / (okCount + nokCount) * 100, 2), \"%\"\n",
    "    print \"    F1 score:  \", f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print \"    Precision: \", precision_score(y_true, y_pred, average=\"macro\")\n",
    "    print \"    Recall:    \", recall_score(y_true, y_pred, average=\"macro\")\n",
    "    print \"\\n##########  ML MODEL CHANGED ########## \\n\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "IN ORDER TO GET THE SENTENCE'S LEMMAS\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def LemmaString(sentence):\n",
    "    words = nltk.tokenize.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    LemmaSentence = \"\"\n",
    "    for tag in tags:\n",
    "        # Special treatment for verbs\n",
    "        if tag[1] == 'VBP' or tag[1] == 'VBP' or tag[1] == 'VBZ' or tag[1] == 'VBG' or tag[1] == 'VBD':\n",
    "            lemma = wordnet_lemmatizer.lemmatize(tag[0], pos='v')\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(tag[0])\n",
    "        LemmaSentence += str(lemma) + \" \"\n",
    "    return LemmaSentence\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FOR CLEANING PROCESS\n",
    "\"\"\"\n",
    "\n",
    "def cleanstopwordsandsymbols(sentence):\n",
    "    words = nltk.tokenize.word_tokenize(sentence)\n",
    "    sentence = nltk.pos_tag(words)\n",
    "    csentence = sentence\n",
    "    for word in sentence:\n",
    "        #print str(word[0])\n",
    "        #if word != \"``\" and word != ',' and word != \"''\":\n",
    "        if str(word[0]) == \".\" or str(word[0]) == \"``\" or str(word[0]) == \",\" or str(word[0]) == \"''\" or str(word[0]) == \"'\":\n",
    "            csentence.remove(word)\n",
    "        else:\n",
    "            for jword in stopWords:\n",
    "                if str(word[0]) == str(jword):\n",
    "                    csentence.remove(word)\n",
    "    sentence = \"\"\n",
    "    for word in csentence:\n",
    "        sentence += \" \" + str(word[0])\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingPath = 'C:\\\\Users\\\\AlvaroRomero\\\\Google Drive\\\\MASTER\\\\IHLT\\\\IHLT-eval-framework\\\\train\\\\msr_paraphrase_train_input.txt'\n",
    "testPath = 'C:\\\\Users\\\\AlvaroRomero\\\\Google Drive\\\\MASTER\\\\IHLT\\\\IHLT-eval-framework\\\\test\\\\msr_paraphrase_test_input.txt'\n",
    "\n",
    "\"\"\"TRAINING\"\"\"\n",
    "iniFile = io.open(trainingPath, \"r\", encoding=\"utf-8\")\n",
    "pairsOfSentencesTraining = []\n",
    "for oneline in iniFile:\n",
    "    pairsOfSentencesTraining.append(oneline.split('\\t'))\n",
    "iniFile.close()\n",
    "\n",
    "labelsFile = io.open(trainingPath, \"r\", encoding=\"utf-8\")\n",
    "similarityLabelsTraining = []\n",
    "for oneline in labelsFile:\n",
    "    if oneline.replace(\"\\n\",\"\").encode('utf-8').find(\"1\") != -1:\n",
    "        similarityLabelsTraining.append(1)\n",
    "    else:\n",
    "        similarityLabelsTraining.append(0)\n",
    "labelsFile.close()\n",
    "\n",
    "\"\"\"TEST\"\"\"\n",
    "iniFile = io.open(testPath, \"r\", encoding=\"utf-8\")\n",
    "pairsOfSentencesTest = []\n",
    "for oneline in iniFile:\n",
    "    pairsOfSentencesTest.append(oneline.split('\\t'))\n",
    "iniFile.close()\n",
    "\n",
    "labelsFile = io.open(testPath, \"r\", encoding=\"utf-8\")\n",
    "similarityLabelsTest = []\n",
    "for oneline in labelsFile:\n",
    "    if oneline.replace(\"\\n\",\"\").encode('utf-8').find(\"1\") != -1:\n",
    "        similarityLabelsTest.append(1)\n",
    "    else:\n",
    "        similarityLabelsTest.append(0)\n",
    "labelsFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Machine Learning Models.\n",
    "\n",
    "1. Random Forest version 1\n",
    "2. Random Forest version 2\n",
    "3. Random Forest version 3\n",
    "4. 1-NN\n",
    "5. 3-NN\n",
    "6. 5-NN\n",
    "7. SVM - RBF\n",
    "8. SVM - Poly\n",
    "9. SVM - Linear version 1\n",
    "10. SVM - Linear version 2\n",
    "11. Multilayer Perceptron version 1\n",
    "12. Multilayer Perceptron version 2\n",
    "13. Multilayer Perceptron version 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ML MODELS\n",
    "\"\"\"\n",
    "\n",
    "names = [\n",
    "         \"Random Forest 1\",\n",
    "         \"Random Forest 2\",\n",
    "         \"Random Forest 3\",\n",
    "         \"KNN (1-NN)\",\n",
    "         \"KNN (3-NN)\",\n",
    "         \"KNN (5-NN)\",\n",
    "         \"SVM v1\",\n",
    "         \"SVM v2\",\n",
    "         \"SVM v3\",\n",
    "         \"Linear SVM\",\n",
    "         \"MLP v1\",\n",
    "         \"MLP v2\",\n",
    "         \"MLP v3\"]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=5, max_features=3),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=2),\n",
    "    KNeighborsClassifier(1),\n",
    "    KNeighborsClassifier(3),\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel='rbf', gamma=0.6, C=100.0),\n",
    "    SVC(kernel='poly', degree = 4, C=100.0),\n",
    "    SVC(kernel='linear', C=100.0, random_state=40),\n",
    "    LinearSVC(C=100.0, random_state=42),\n",
    "    MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(4, 2), random_state=13, max_iter=100),\n",
    "    MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 10, 5), random_state=3, max_iter=6000),\n",
    "    MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15, 7), random_state=1, max_iter=500)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "### Syntactic dimension: triples\n",
    "For each pair of training sentences, we store the comparison metrics mentioned above. Once we have done this, we build a ML model and test it con same features of the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "definitiveTraining = []\n",
    "definitiveTrainingPair = []\n",
    "for sentences in pairsOfSentencesTraining:\n",
    "    definitiveTraining = []\n",
    "    try:\n",
    "        for sentence in sentences:\n",
    "            triplesSentence = []\n",
    "            parse, = parser.raw_parse(sentence)\n",
    "            for governor, dep, dependent in parse.triples():\n",
    "                #definitive.append(governor, dep, dependent)\n",
    "                aux = ''\n",
    "                string_governor = '(' + governor[0].encode('ascii', 'ignore') + ',' + governor[1].encode('ascii', 'ignore') + ')'\n",
    "                string_dependent = '(' + dependent[0].encode('ascii', 'ignore') + ',' + dependent[1].encode('ascii', 'ignore') + ')'\n",
    "                aux += string_governor + ' ' + dep.encode('ascii', 'ignore') + ' ' + string_dependent\n",
    "                triplesSentence.append(aux)\n",
    "            definitiveTraining.append(triplesSentence)\n",
    "        definitiveTrainingPair.append(definitiveTraining)\n",
    "    except:\n",
    "        print sentence\n",
    "\n",
    "definitiveTest = []\n",
    "definitiveTestPair = []\n",
    "for sentences in pairsOfSentencesTest:\n",
    "    definitiveTest =[]\n",
    "    for sentence in sentences:\n",
    "        triplesSentence = []\n",
    "        parse, = parser.raw_parse(sentence)\n",
    "        for governor, dep, dependent in parse.triples():\n",
    "            aux = ''\n",
    "            string_governor = '(' + governor[0].encode('ascii', 'ignore') + ',' + governor[1].encode('ascii', 'ignore') + ')'\n",
    "            string_dependent = '(' + dependent[0].encode('ascii', 'ignore') + ',' + dependent[1].encode('ascii', 'ignore') + ')'\n",
    "            aux += string_governor + ' ' + dep.encode('ascii', 'ignore') + ' ' + string_dependent\n",
    "            triplesSentence.append(aux)\n",
    "        definitiveTest.append(triplesSentence)\n",
    "    definitiveTestPair.append(definitiveTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRIPLES TRAINING\n",
    "\"\"\"\n",
    "data = []\n",
    "for pair in definitiveTrainingPair:\n",
    "    foreachpair = []\n",
    "    sentence1 = pair[0]\n",
    "    sentence2 = pair[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TRIPLES TEST\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair in definitiveTestPair:\n",
    "    foreachpair = []\n",
    "    sentence1 = pair[0]\n",
    "    sentence2 = pair[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-----------------------------------------------\n",
      "\t------------------ TRIPLES --------------------\n",
      "\t-----------------------------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.735072463768  reject=  0.996041171813  accept=  0.021645021645\n",
      "    Matched results:     1268            73.51 %\n",
      "    No matched results:  457            26.49 %\n",
      "    F1 score:   0.444105968391\n",
      "    Precision:  0.701169590643\n",
      "    Recall:     0.508843096729\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.726376811594  reject=  0.945368171021  accept=  0.127705627706\n",
      "    Matched results:     1253            72.64 %\n",
      "    No matched results:  472            27.36 %\n",
      "    F1 score:   0.517482517483\n",
      "    Precision:  0.604294673607\n",
      "    Recall:     0.536536899364\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.734492753623  reject=  0.988915281077  accept=  0.038961038961\n",
      "    Matched results:     1267            73.45 %\n",
      "    No matched results:  458            26.55 %\n",
      "    F1 score:   0.458967693513\n",
      "    Precision:  0.650121825162\n",
      "    Recall:     0.513938160019\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.631884057971  reject=  0.762470308789  accept=  0.274891774892\n",
      "    Matched results:     1090            63.19 %\n",
      "    No matched results:  635            36.81 %\n",
      "    F1 score:   0.518882133095\n",
      "    Precision:  0.519667259664\n",
      "    Recall:     0.51868104184\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.670144927536  reject=  0.839271575614  accept=  0.207792207792\n",
      "    Matched results:     1156            67.01 %\n",
      "    No matched results:  569            32.99 %\n",
      "    F1 score:   0.520348389726\n",
      "    Precision:  0.532204121264\n",
      "    Recall:     0.523531891703\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.691594202899  reject=  0.882026920032  accept=  0.170995670996\n",
      "    Matched results:     1193            69.16 %\n",
      "    No matched results:  532            30.84 %\n",
      "    F1 score:   0.518115942029\n",
      "    Precision:  0.545323102345\n",
      "    Recall:     0.526511295514\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.733913043478  reject=  0.998416468725  accept=  0.0108225108225\n",
      "    Matched results:     1266            73.39 %\n",
      "    No matched results:  459            26.61 %\n",
      "    F1 score:   0.433673392753\n",
      "    Precision:  0.72413936471\n",
      "    Recall:     0.504619489774\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.732753623188  reject=  0.994457640538  accept=  0.017316017316\n",
      "    Matched results:     1264            73.28 %\n",
      "    No matched results:  461            26.72 %\n",
      "    F1 score:   0.439240375116\n",
      "    Precision:  0.633918128655\n",
      "    Recall:     0.505886828927\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.735072463768  reject=  0.995249406176  accept=  0.0238095238095\n",
      "    Matched results:     1268            73.51 %\n",
      "    No matched results:  457            26.49 %\n",
      "    F1 score:   0.446054378126\n",
      "    Precision:  0.691503650641\n",
      "    Recall:     0.509529464993\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t-----------------------------------------------\"\n",
    "print \"\\t------------------ TRIPLES --------------------\"\n",
    "print \"\\t-----------------------------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "### Tests:\n",
    "\n",
    "1. Only with words results. For each pair of sentences the stored vector is [ Difflib distance, Tf/IDF distance, Cosine distance, Paraphrase].\n",
    "2. With words and lemmas. Same vector as point (1) plus the results of comparison metrics with lemmas.\n",
    "3. Words' results with cleaning process.\n",
    "4. Words' and lemmas' results, both with cleaning process.\n",
    "5. Words', lemmas' and triples' results.\n",
    "6. Words' and triples' results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (ONLY WITH WORDS)\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair in pairsOfSentencesTraining:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    #difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    #Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (ONLY WITH WORDS)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair in pairsOfSentencesTest:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    #difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    #Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t \t----------------------\n",
      "\t \t----- Only words -----\n",
      "\t \t----------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.747246376812  reject=  0.984164687253  accept=  0.0995670995671\n",
      "    Matched results:     1289            74.72 %\n",
      "    No matched results:  436            25.28 %\n",
      "    F1 score:   0.512514778172\n",
      "    Precision:  0.723108115513\n",
      "    Recall:     0.54186589341\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.735072463768  reject=  0.956452889945  accept=  0.12987012987\n",
      "    Matched results:     1268            73.51 %\n",
      "    No matched results:  457            26.49 %\n",
      "    F1 score:   0.524452546599\n",
      "    Precision:  0.63602484472\n",
      "    Recall:     0.543161509907\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.749565217391  reject=  0.988915281077  accept=  0.0952380952381\n",
      "    Matched results:     1293            74.96 %\n",
      "    No matched results:  432            25.04 %\n",
      "    F1 score:   0.510895248097\n",
      "    Precision:  0.753935419813\n",
      "    Recall:     0.542076688157\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.645797101449  reject=  0.764053840063  accept=  0.322510822511\n",
      "    Matched results:     1114            64.58 %\n",
      "    No matched results:  611            35.42 %\n",
      "    F1 score:   0.543688135047\n",
      "    Precision:  0.54420970266\n",
      "    Recall:     0.543282331287\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.694492753623  reject=  0.857482185273  accept=  0.248917748918\n",
      "    Matched results:     1198            69.45 %\n",
      "    No matched results:  527            30.55 %\n",
      "    F1 score:   0.554069187644\n",
      "    Precision:  0.573586582909\n",
      "    Recall:     0.553199967095\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.691014492754  reject=  0.874901029295  accept=  0.188311688312\n",
      "    Matched results:     1192            69.1 %\n",
      "    No matched results:  533            30.9 %\n",
      "    F1 score:   0.525898764555\n",
      "    Precision:  0.550861831219\n",
      "    Recall:     0.531606358804\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.742608695652  reject=  0.986539984165  accept=  0.0757575757576\n",
      "    Matched results:     1281            74.26 %\n",
      "    No matched results:  444            25.74 %\n",
      "    F1 score:   0.492480306195\n",
      "    Precision:  0.708923398777\n",
      "    Recall:     0.531148779961\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.743768115942  reject=  0.987331749802  accept=  0.0779220779221\n",
      "    Matched results:     1283            74.38 %\n",
      "    No matched results:  442            25.62 %\n",
      "    F1 score:   0.494766430942\n",
      "    Precision:  0.718837647708\n",
      "    Recall:     0.532626913862\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t \\t----------------------\"\n",
    "print \"\\t \\t----- Only words -----\"\n",
    "print \"\\t \\t----------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words and lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (WORDS AND LEMMAS)\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair in pairsOfSentencesTraining:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    # LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (WORDS AND LEMMAS)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair in pairsOfSentencesTest:\n",
    "    # WORDS\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    #LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t----------------------------\n",
      "\t----- Words and lemmas -----\n",
      "\t----------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.744927536232  reject=  0.98495645289  accept=  0.0887445887446\n",
      "    Matched results:     1285            74.49 %\n",
      "    No matched results:  440            25.51 %\n",
      "    F1 score:   0.503407449281\n",
      "    Precision:  0.71524024024\n",
      "    Recall:     0.536850520817\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.724637681159  reject=  0.946159936659  accept=  0.119047619048\n",
      "    Matched results:     1250            72.46 %\n",
      "    No matched results:  475            27.54 %\n",
      "    F1 score:   0.511120060858\n",
      "    Precision:  0.596548521665\n",
      "    Recall:     0.532603777853\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.746086956522  reject=  0.985748218527  accept=  0.0909090909091\n",
      "    Matched results:     1287            74.61 %\n",
      "    No matched results:  438            25.39 %\n",
      "    F1 score:   0.505664688148\n",
      "    Precision:  0.723873873874\n",
      "    Recall:     0.538328654718\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.63652173913  reject=  0.751385589865  accept=  0.322510822511\n",
      "    Matched results:     1098            63.65 %\n",
      "    No matched results:  627            36.35 %\n",
      "    F1 score:   0.536922665239\n",
      "    Precision:  0.536897618713\n",
      "    Recall:     0.536948206188\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.67768115942  reject=  0.836104513064  accept=  0.244588744589\n",
      "    Matched results:     1169            67.77 %\n",
      "    No matched results:  556            32.23 %\n",
      "    F1 score:   0.540303377723\n",
      "    Precision:  0.552363211744\n",
      "    Recall:     0.540346628826\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.704927536232  reject=  0.882818685669  accept=  0.218614718615\n",
      "    Matched results:     1216            70.49 %\n",
      "    No matched results:  509            29.51 %\n",
      "    F1 score:   0.549136322813\n",
      "    Precision:  0.58052127208\n",
      "    Recall:     0.550716702142\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.740289855072  reject=  0.996832937451  accept=  0.038961038961\n",
      "    Matched results:     1277            74.03 %\n",
      "    No matched results:  448            25.97 %\n",
      "    F1 score:   0.461667493299\n",
      "    Precision:  0.778732717664\n",
      "    Recall:     0.517896988206\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.702608695652  reject=  0.832145684877  accept=  0.348484848485\n",
      "    Matched results:     1212            70.26 %\n",
      "    No matched results:  513            29.74 %\n",
      "    F1 score:   0.594726417147\n",
      "    Precision:  0.604501126323\n",
      "    Recall:     0.590315266681\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.733913043478  reject=  0.995249406176  accept=  0.0194805194805\n",
      "    Matched results:     1266            73.39 %\n",
      "    No matched results:  459            26.61 %\n",
      "    F1 score:   0.441673171753\n",
      "    Precision:  0.667543859649\n",
      "    Recall:     0.507364962828\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.747246376812  reject=  0.986539984165  accept=  0.0930735930736\n",
      "    Matched results:     1289            74.72 %\n",
      "    No matched results:  436            25.28 %\n",
      "    F1 score:   0.507921927015\n",
      "    Precision:  0.732507507508\n",
      "    Recall:     0.539806788619\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.740869565217  reject=  0.977038796516  accept=  0.0952380952381\n",
      "    Matched results:     1278            74.09 %\n",
      "    No matched results:  447            25.91 %\n",
      "    F1 score:   0.505570606435\n",
      "    Precision:  0.674856545822\n",
      "    Recall:     0.536138445877\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t----------------------------\"\n",
    "print \"\\t----- Words and lemmas -----\"\n",
    "print \"\\t----------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words [cleaning process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (ONLY WITH WORDS [Cleaning process])\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair in pairsOfSentencesTraining:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "    sentence1 = cleanstopwordsandsymbols(sentence1)\n",
    "    sentence2 = cleanstopwordsandsymbols(sentence2)\n",
    "\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (ONLY WITH WORDS)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair in pairsOfSentencesTest:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "    sentence1 = cleanstopwordsandsymbols(sentence1)\n",
    "    sentence2 = cleanstopwordsandsymbols(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-----------------------------------------\n",
      "\t----- Only words [Cleaning process] -----\n",
      "\t-----------------------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.744347826087  reject=  0.98495645289  accept=  0.0865800865801\n",
      "    Matched results:     1284            74.43 %\n",
      "    No matched results:  441            25.57 %\n",
      "    F1 score:   0.501493765764\n",
      "    Precision:  0.712332390583\n",
      "    Recall:     0.535768269735\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.726376811594  reject=  0.940617577197  accept=  0.140692640693\n",
      "    Matched results:     1253            72.64 %\n",
      "    No matched results:  472            27.36 %\n",
      "    F1 score:   0.525108253388\n",
      "    Precision:  0.606906264083\n",
      "    Recall:     0.540655108945\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.743768115942  reject=  0.987331749802  accept=  0.0779220779221\n",
      "    Matched results:     1283            74.38 %\n",
      "    No matched results:  442            25.62 %\n",
      "    F1 score:   0.494766430942\n",
      "    Precision:  0.718837647708\n",
      "    Recall:     0.532626913862\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.648695652174  reject=  0.762470308789  accept=  0.337662337662\n",
      "    Matched results:     1119            64.87 %\n",
      "    No matched results:  606            35.13 %\n",
      "    F1 score:   0.550266394077\n",
      "    Precision:  0.550485255692\n",
      "    Recall:     0.550066323225\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.67768115942  reject=  0.850356294537  accept=  0.205627705628\n",
      "    Matched results:     1169            67.77 %\n",
      "    No matched results:  556            32.23 %\n",
      "    F1 score:   0.524535193616\n",
      "    Precision:  0.539911397601\n",
      "    Recall:     0.527992000082\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.708405797101  reject=  0.89469517023  accept=  0.199134199134\n",
      "    Matched results:     1222            70.84 %\n",
      "    No matched results:  503            29.16 %\n",
      "    F1 score:   0.542891325959\n",
      "    Precision:  0.581111111111\n",
      "    Recall:     0.546914684682\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.741449275362  reject=  0.980997624703  accept=  0.0865800865801\n",
      "    Matched results:     1279            74.14 %\n",
      "    No matched results:  446            25.86 %\n",
      "    F1 score:   0.4997802375\n",
      "    Precision:  0.685468091511\n",
      "    Recall:     0.533788855642\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.742608695652  reject=  0.980205859066  accept=  0.0930735930736\n",
      "    Matched results:     1281            74.26 %\n",
      "    No matched results:  444            25.74 %\n",
      "    F1 score:   0.505104678211\n",
      "    Precision:  0.689743157372\n",
      "    Recall:     0.53663972607\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t-----------------------------------------\"\n",
    "print \"\\t----- Only words [Cleaning process] -----\"\n",
    "print \"\\t-----------------------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words and lemmas [cleaning process]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (WORDS AND LEMMAS) [Cleaning process]\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair in pairsOfSentencesTraining:\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "    sentence1 = cleanstopwordsandsymbols(sentence1)\n",
    "    sentence2 = cleanstopwordsandsymbols(sentence2)\n",
    "\n",
    "    #difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    #Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "\n",
    "    # LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (WORDS AND LEMMAS)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair in pairsOfSentencesTest:\n",
    "    #WORDS\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "    sentence1 = cleanstopwordsandsymbols(sentence1)\n",
    "    sentence2 = cleanstopwordsandsymbols(sentence2)\n",
    "\n",
    "    #difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    #Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    #LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-----------------------------------------------\n",
      "\t----- Words and lemmas [Cleaning process] -----\n",
      "\t-----------------------------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.740289855072  reject=  0.977830562154  accept=  0.0909090909091\n",
      "    Matched results:     1277            74.03 %\n",
      "    No matched results:  448            25.97 %\n",
      "    F1 score:   0.50218246095\n",
      "    Precision:  0.673111782477\n",
      "    Recall:     0.534369826531\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.733333333333  reject=  0.961203483769  accept=  0.11038961039\n",
      "    Matched results:     1265            73.33 %\n",
      "    No matched results:  460            26.67 %\n",
      "    F1 score:   0.511107441764\n",
      "    Precision:  0.628538461538\n",
      "    Recall:     0.535796547079\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.740289855072  reject=  0.983372921615  accept=  0.0757575757576\n",
      "    Matched results:     1277            74.03 %\n",
      "    No matched results:  448            25.97 %\n",
      "    F1 score:   0.491169204675\n",
      "    Precision:  0.684579089275\n",
      "    Recall:     0.529565248686\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.64  reject=  0.763262074426  accept=  0.30303030303\n",
      "    Matched results:     1104            64.0 %\n",
      "    No matched results:  621            36.0 %\n",
      "    F1 score:   0.5335704324\n",
      "    Precision:  0.534258901717\n",
      "    Recall:     0.533146188728\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.674782608696  reject=  0.840063341251  accept=  0.222943722944\n",
      "    Matched results:     1164            67.48 %\n",
      "    No matched results:  561            32.52 %\n",
      "    F1 score:   0.52974229066\n",
      "    Precision:  0.542444008312\n",
      "    Recall:     0.531503532097\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.692753623188  reject=  0.882818685669  accept=  0.17316017316\n",
      "    Matched results:     1195            69.28 %\n",
      "    No matched results:  530            30.72 %\n",
      "    F1 score:   0.519927536232\n",
      "    Precision:  0.547850086137\n",
      "    Recall:     0.527989429415\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.732753623188  reject=  1.0  accept=  0.0021645021645\n",
      "    Matched results:     1264            73.28 %\n",
      "    No matched results:  461            26.72 %\n",
      "    F1 score:   0.424992100398\n",
      "    Precision:  0.866299303944\n",
      "    Recall:     0.501082251082\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.731014492754  reject=  0.998416468725  accept=  0.0\n",
      "    Matched results:     1261            73.1 %\n",
      "    No matched results:  464            26.9 %\n",
      "    F1 score:   0.422304085733\n",
      "    Precision:  0.3659315148\n",
      "    Recall:     0.499208234363\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.743188405797  reject=  0.982581155978  accept=  0.0887445887446\n",
      "    Matched results:     1282            74.32 %\n",
      "    No matched results:  443            25.68 %\n",
      "    F1 score:   0.502368742369\n",
      "    Precision:  0.698742192425\n",
      "    Recall:     0.535662872361\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.740869565217  reject=  0.977830562154  accept=  0.0930735930736\n",
      "    Matched results:     1278            74.09 %\n",
      "    No matched results:  447            25.91 %\n",
      "    F1 score:   0.504055607261\n",
      "    Precision:  0.676154265375\n",
      "    Recall:     0.535452077614\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t-----------------------------------------------\"\n",
    "print \"\\t----- Words and lemmas [Cleaning process] -----\"\n",
    "print \"\\t-----------------------------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Words, lemmas and triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (WORDS, LEMMAS AND TRIPLES)\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair, pairTriples in zip(pairsOfSentencesTraining, definitiveTrainingPair):\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    # LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    #TRIPLES\n",
    "    sentence1 = pairTriples[0]\n",
    "    sentence2 = pairTriples[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (WORDS,LEMMAS AND TRIPLES)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair, pairTriples in zip(pairsOfSentencesTest, definitiveTestPair):\n",
    "    # WORDS\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    #LEMMAS\n",
    "    sentence1 = LemmaString(sentence1)\n",
    "    sentence2 = LemmaString(sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    # TRIPLES\n",
    "    sentence1 = pairTriples[0]\n",
    "    sentence2 = pairTriples[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-------------------------------------\n",
      "\t----- Words, lemmas and triples -----\n",
      "\t-------------------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.748405797101  reject=  0.980997624703  accept=  0.112554112554\n",
      "    Matched results:     1291            74.84 %\n",
      "    No matched results:  434            25.16 %\n",
      "    F1 score:   0.522135044324\n",
      "    Precision:  0.717787494813\n",
      "    Recall:     0.546775868629\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.743768115942  reject=  0.955661124307  accept=  0.164502164502\n",
      "    Matched results:     1283            74.38 %\n",
      "    No matched results:  442            25.62 %\n",
      "    F1 score:   0.550565175565\n",
      "    Precision:  0.66672373452\n",
      "    Recall:     0.560081644405\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.750724637681  reject=  0.985748218527  accept=  0.108225108225\n",
      "    Matched results:     1295            75.07 %\n",
      "    No matched results:  430            24.93 %\n",
      "    F1 score:   0.520709485655\n",
      "    Precision:  0.743325996663\n",
      "    Recall:     0.546986663376\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 1 vecinos\n",
      "    acc=  0.651014492754  reject=  0.760095011876  accept=  0.352813852814\n",
      "    Matched results:     1123            65.1 %\n",
      "    No matched results:  602            34.9 %\n",
      "    F1 score:   0.556296829282\n",
      "    Precision:  0.55614766812\n",
      "    Recall:     0.556454432345\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 3 vecinos\n",
      "    acc=  0.689275362319  reject=  0.840855106888  accept=  0.274891774892\n",
      "    Matched results:     1189            68.93 %\n",
      "    No matched results:  536            31.07 %\n",
      "    F1 score:   0.560007613972\n",
      "    Precision:  0.573697775721\n",
      "    Recall:     0.55787344089\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN 5 vecinos\n",
      "    acc=  0.699130434783  reject=  0.880443388757  accept=  0.203463203463\n",
      "    Matched results:     1206            69.91 %\n",
      "    No matched results:  519            30.09 %\n",
      "    F1 score:   0.538351705073\n",
      "    Precision:  0.56751241037\n",
      "    Recall:     0.54195329611\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.742028985507  reject=  0.993665874901  accept=  0.0541125541126\n",
      "    Matched results:     1280            74.2 %\n",
      "    No matched results:  445            25.8 %\n",
      "    F1 score:   0.475208942214\n",
      "    Precision:  0.749650762949\n",
      "    Recall:     0.523889214507\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.733333333333  reject=  0.994457640538  accept=  0.0194805194805\n",
      "    Matched results:     1265            73.33 %\n",
      "    No matched results:  460            26.67 %\n",
      "    F1 score:   0.441439488222\n",
      "    Precision:  0.648716354593\n",
      "    Recall:     0.506969080009\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.740289855072  reject=  0.98495645289  accept=  0.0714285714286\n",
      "    Matched results:     1277            74.03 %\n",
      "    No matched results:  448            25.97 %\n",
      "    F1 score:   0.487908056701\n",
      "    Precision:  0.689094900915\n",
      "    Recall:     0.528192512159\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.751304347826  reject=  0.976247030879  accept=  0.136363636364\n",
      "    Matched results:     1296            75.13 %\n",
      "    No matched results:  429            24.87 %\n",
      "    F1 score:   0.539420249265\n",
      "    Precision:  0.716467030361\n",
      "    Recall:     0.556305333621\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.743768115942  reject=  0.977038796516  accept=  0.106060606061\n",
      "    Matched results:     1283            74.38 %\n",
      "    No matched results:  442            25.62 %\n",
      "    F1 score:   0.514795723559\n",
      "    Precision:  0.688723086264\n",
      "    Recall:     0.541549701288\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t-------------------------------------\"\n",
    "print \"\\t----- Words, lemmas and triples -----\"\n",
    "print \"\\t-------------------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words and triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA MATRIX FOR TRAINING (WORDS AND TRIPLES)\n",
    "\"\"\"\n",
    "\n",
    "data = []\n",
    "for pair, pairTriples in zip(pairsOfSentencesTraining, definitiveTrainingPair):\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    #TRIPLES\n",
    "    sentence1 = pairTriples[0]\n",
    "    sentence2 = pairTriples[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    data.append(foreachpair)\n",
    "\n",
    "\"\"\"\n",
    "DATA MATRIX FOR TEST (WORDS,LEMMAS AND TRIPLES)\n",
    "\"\"\"\n",
    "\n",
    "dataTest = []\n",
    "for pair, pairTriples in zip(pairsOfSentencesTest, definitiveTestPair):\n",
    "    # WORDS\n",
    "    foreachpair = []\n",
    "    sentence1 = unicodedata.normalize('NFKD', pair[0]).encode('ascii', 'ignore')\n",
    "    sentence2 = unicodedata.normalize('NFKD', pair[1]).encode('ascii', 'ignore')\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "    #Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "\n",
    "    # TRIPLES\n",
    "    sentence1 = pairTriples[0]\n",
    "    sentence2 = pairTriples[1]\n",
    "    sentence1.sort(key=str.lower)\n",
    "    sentence2.sort(key=str.lower)\n",
    "    sentence1 = '-'.join(str(x) for x in sentence1)\n",
    "    sentence2 = '-'.join(str(y) for y in sentence2)\n",
    "\n",
    "    # difflib\n",
    "    foreachpair.append(difflib.SequenceMatcher(None, sentence1, sentence2).ratio())\n",
    "    # Tfidf\n",
    "\n",
    "    tfidf = vect.fit_transform([sentence1, sentence2])\n",
    "    foreachpair.append((tfidf * tfidf.T).A[0][1])\n",
    "\n",
    "    # Cosine\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    foreachpair.append(get_cosine(vector1, vector2))\n",
    "    dataTest.append(foreachpair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-----------------------------\n",
      "\t----- Words and triples -----\n",
      "\t-----------------------------\n",
      " \n",
      "\n",
      "Random Forest 1\n",
      "    acc=  0.754202898551  reject=  0.986539984165  accept=  0.119047619048\n",
      "    Matched results:     1301            75.42 %\n",
      "    No matched results:  424            24.58 %\n",
      "    F1 score:   0.53029392272\n",
      "    Precision:  0.758834946562\n",
      "    Recall:     0.552793801606\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 2\n",
      "    acc=  0.731594202899  reject=  0.952494061758  accept=  0.127705627706\n",
      "    Matched results:     1262            73.16 %\n",
      "    No matched results:  463            26.84 %\n",
      "    F1 score:   0.52085891742\n",
      "    Precision:  0.622432160909\n",
      "    Recall:     0.540099844732\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Random Forest 3\n",
      "    acc=  0.750724637681  reject=  0.983372921615  accept=  0.114718614719\n",
      "    Matched results:     1295            75.07 %\n",
      "    No matched results:  430            24.93 %\n",
      "    F1 score:   0.525098853707\n",
      "    Precision:  0.734243783456\n",
      "    Recall:     0.549045768167\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN (1-NN)\n",
      "    acc=  0.653913043478  reject=  0.779097387173  accept=  0.311688311688\n",
      "    Matched results:     1128            65.39 %\n",
      "    No matched results:  597            34.61 %\n",
      "    F1 score:   0.546337595401\n",
      "    Precision:  0.548092950289\n",
      "    Recall:     0.545392849431\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN (3-NN)\n",
      "    acc=  0.689855072464  reject=  0.851148060174  accept=  0.248917748918\n",
      "    Matched results:     1190            68.99 %\n",
      "    No matched results:  535            31.01 %\n",
      "    F1 score:   0.550699236864\n",
      "    Precision:  0.56775772514\n",
      "    Recall:     0.550032904546\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "KNN (5-NN)\n",
      "    acc=  0.707826086957  reject=  0.893903404592  accept=  0.199134199134\n",
      "    Matched results:     1221            70.78 %\n",
      "    No matched results:  504            29.22 %\n",
      "    F1 score:   0.542482697068\n",
      "    Precision:  0.580124212602\n",
      "    Recall:     0.546518801863\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v1\n",
      "    acc=  0.737971014493  reject=  0.998416468725  accept=  0.025974025974\n",
      "    Matched results:     1273            73.8 %\n",
      "    No matched results:  452            26.2 %\n",
      "    F1 score:   0.449218153973\n",
      "    Precision:  0.797069382984\n",
      "    Recall:     0.51219524735\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v2\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "SVM v3\n",
      "    acc=  0.732173913043  reject=  1.0  accept=  0.0\n",
      "    Matched results:     1263            73.22 %\n",
      "    No matched results:  462            26.78 %\n",
      "    F1 score:   0.422690763052\n",
      "    Precision:  0.366086956522\n",
      "    Recall:     0.5\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "Linear SVM\n",
      "    acc=  0.734492753623  reject=  0.996832937451  accept=  0.017316017316\n",
      "    Matched results:     1267            73.45 %\n",
      "    No matched results:  458            26.55 %\n",
      "    F1 score:   0.4399287124\n",
      "    Precision:  0.700817279626\n",
      "    Recall:     0.507074477383\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v1\n",
      "    acc=  0.738550724638  reject=  0.995249406176  accept=  0.0367965367965\n",
      "    Matched results:     1274            73.86 %\n",
      "    No matched results:  451            26.14 %\n",
      "    F1 score:   0.458997583491\n",
      "    Precision:  0.73883666275\n",
      "    Recall:     0.516022971486\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v2\n",
      "    acc=  0.745507246377  reject=  0.977830562154  accept=  0.11038961039\n",
      "    Matched results:     1286            74.55 %\n",
      "    No matched results:  439            25.45 %\n",
      "    F1 score:   0.518814387626\n",
      "    Precision:  0.69793669348\n",
      "    Recall:     0.544110086272\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n",
      "MLP v3\n",
      "    acc=  0.748985507246  reject=  0.980205859066  accept=  0.116883116883\n",
      "    Matched results:     1292            74.9 %\n",
      "    No matched results:  433            25.1 %\n",
      "    F1 score:   0.52539095636\n",
      "    Precision:  0.717835335374\n",
      "    Recall:     0.548544487974\n",
      "\n",
      "##########  ML MODEL CHANGED ########## \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"\\t-----------------------------\"\n",
    "print \"\\t----- Words and triples -----\"\n",
    "print \"\\t-----------------------------\\n \\n\"\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(data, similarityLabelsTraining)\n",
    "    TN, FP, FN, TP = confusion_matrix(similarityLabelsTest, clf.predict(dataTest)).ravel()\n",
    "    printResults(similarityLabelsTest, clf.predict(dataTest), TN, FP, FN, TP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
